{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mwq6HkgCORB8"
      },
      "outputs": [],
      "source": [
        "!pip install qiskit-ibmq-provider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2osayhDC5kCz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "id": "sqKUtKwX_7is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcVbGpHiJDld"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/mit-han-lab/torchquantum.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3w-m5cwJR01"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_directory = os.getcwd()\n",
        "print(\"Current Directory:\", current_directory)\n",
        "new_directory = os.path.join(current_directory, 'torchquantum')\n",
        "os.chdir(new_directory)\n",
        "new_current_directory = os.getcwd()\n",
        "print(\"New Current Directory:\", new_current_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86oKi1k5JpGy"
      },
      "outputs": [],
      "source": [
        "!pip install --editable ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKhECYgmIupW"
      },
      "outputs": [],
      "source": [
        "# IMPORTS -----------------------------------------------\n",
        "import threading\n",
        "import random\n",
        "import time\n",
        "import csv\n",
        "import datetime\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchquantum as tq\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "#import qiskit-ibmq-provider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEKh9cYKs_lH"
      },
      "outputs": [],
      "source": [
        "# CMSCA CODE -----------------------------------------------\n",
        "# Server class\n",
        "class Server:\n",
        "    # Constructor\n",
        "    def __init__(self, limit):\n",
        "        self.limit = limit                      # limit for number of workers\n",
        "        self.current_workers = 0                # current number of workers who are connected\n",
        "        self.lock = threading.Lock()            # mutex lock for when max workers reached\n",
        "        self.stop_event = threading.Event()     # enables us to stop the server and workers after a timelimit so we can print worker metrics\n",
        "        self.state = {}\n",
        "        self.all_states = []\n",
        "\n",
        "    # A worker connects\n",
        "    def connect(self):\n",
        "        with self.lock:                             # mutex for multithreading\n",
        "            if self.current_workers < self.limit:   # check current num workers against worker limit\n",
        "                self.current_workers += 1           # increment number of current workers\n",
        "                return True                         # successful connection\n",
        "            return False                            # connection refused\n",
        "\n",
        "    # A worker disconnects\n",
        "    def disconnect(self):\n",
        "        with self.lock:                 # mutex for multithreading\n",
        "            self.current_workers -= 1   # decrement number of current workers\n",
        "\n",
        "    # For stopping server after we have run the sim for the desired amount of time\n",
        "    def stop(self):\n",
        "        self.stop_event.set()   # stops the threading\n",
        "\n",
        "# Worker class\n",
        "class Worker(threading.Thread):\n",
        "    # Constructor\n",
        "    def __init__(self, server, priority='normal', identifier=-1, backoff_time=2):\n",
        "        super().__init__()\n",
        "        self.server = server              # server instance for connecting/deconnecting\n",
        "        self.priority = priority          # priority level of worker\n",
        "        self.backoff_time = backoff_time  # initial backoff time\n",
        "        self.init_backoff_time = backoff_time\n",
        "        self.total_work_time = 0          # track total work time to see how starved/successful worker is\n",
        "        self.work_time = 0                # track work time each connection/work/disconnection cycle\n",
        "        self.backoff_count = 0            # track total number of backoffs (failed connection attempts)\n",
        "        self.connection_attempts = 0      # trac total number of connection attempts\n",
        "        self.connection_probability = 0   # Connection probability = 1 - (backoff_count / connection attempts)\n",
        "        self.id = identifier\n",
        "\n",
        "    # Worker loop for simulating connection/work/disconnection cycle\n",
        "    def run(self):\n",
        "        while not self.server.stop_event.is_set():  # Until the threading event ends\n",
        "            connected = self.server.connect()       # Attempt connection\n",
        "            self.connection_attempts += 1\n",
        "            if connected:                           # If connection successful\n",
        "                #print(f\"{self.name}: Connected to server.\")\n",
        "                self.backoff_time = self.init_backoff_time  # Reset backoff time\n",
        "                self.server.state[f\"w{self.id}_backoff\"] = -1\n",
        "                try:\n",
        "                    while not self.server.stop_event.is_set():  # If threading event isn't ending\n",
        "                        time.sleep(1)                           # Sleep 1 second every cycle while connected, this second represents a second of work performed on server\n",
        "                        self.work_time += 1                     # Track work\n",
        "                        if random.random() < 0.25:              # Chance to disconnect every 1 second cycle of work\n",
        "                            break\n",
        "                finally:\n",
        "                    self.server.disconnect()                    # Disconnect from server\n",
        "                    self.total_work_time += self.work_time      # Update work total\n",
        "                    self.work_time = 0                          # Reset cycle tracker\n",
        "                    time.sleep(random.uniform(1, 3))            # Backoff for some time so the worker doesn't immediately reconnect and starve out the others\n",
        "            else:                                   # Connection Failed\n",
        "                self.backoff_count += 1\n",
        "                self.handle_backoff()               # Handle backoff based on priority of worker\n",
        "\n",
        "    # Handle worker backoff after connection refusal based on the priority of the worker\n",
        "    def handle_backoff(self):\n",
        "        self.server.state[f\"w{self.id}_backoff\"] = int(self.backoff_time) + 1\n",
        "        time.sleep(self.backoff_time)\n",
        "        self.backoff_time = min(self.backoff_time * 2, self.init_backoff_time)  # double backoff time every backoff\n",
        "\n",
        "    # Get the total time a worker has performed work while connected to server\n",
        "    def get_total_work_time(self):\n",
        "        return self.total_work_time     # Simpy return tracker variable\n",
        "\n",
        "# Function for lifecycle of server. For example, when we time.sleep(300), we get 5 minutes of server life\n",
        "def server_lifecycle(server, workers, lifecycle=300):\n",
        "    # Run server for 5 minutes\n",
        "    for t in range(lifecycle):\n",
        "        time.sleep(1)\n",
        "        for key in server.state:\n",
        "            if server.state[key] > 0:\n",
        "                server.state[key] = server.state[key] - 1\n",
        "        server.all_states.append(server.state.copy())\n",
        "\n",
        "    server.stop()           # After the <lifecycle> seconds have elapsed, stop the server\n",
        "    #print(\"Server has stopped. Gathering worker information...\")\n",
        "    for worker in workers:  # This loop prints the worker metrics\n",
        "        worker.join()\n",
        "\n",
        "\n",
        "# Instantiate server\n",
        "def simulate(server, worker_count=20, server_life=30, backoff_times=[1, 2, 4]):\n",
        "    workers = []\n",
        "    for i in range(worker_count):\n",
        "        if i % 3 == 0:\n",
        "            worker = Worker(server, priority='high', identifier=i, backoff_time=backoff_times[0])\n",
        "        elif i % 3 == 1:\n",
        "            worker = Worker(server, priority='normal', identifier=i, backoff_time=backoff_times[1])\n",
        "        else:\n",
        "            worker = Worker(server, priority='low', identifier=i, backoff_time=backoff_times[2])\n",
        "        workers.append(worker)\n",
        "        worker.start()\n",
        "\n",
        "    for i in range(len(workers)):\n",
        "        server.state[f\"w{i}_backoff\"] = 0\n",
        "\n",
        "        prio = 0\n",
        "        if workers[i].priority == 'normal':\n",
        "            prio = -1\n",
        "        if workers[i].priority == 'high':\n",
        "            prio = -2\n",
        "        server.state[f\"w{i}_priority\"] = prio\n",
        "\n",
        "    # Start server threading, send workers to server\n",
        "    lifecycle_thread = threading.Thread(target=server_lifecycle, args=(server, workers, server_life))\n",
        "    lifecycle_thread.start()\n",
        "    lifecycle_thread.join()\n",
        "    return workers\n",
        "\n",
        "\n",
        "def write_to_csv(workers, confirm_filename=False):\n",
        "    # Write worker information to CSV\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "    csv_file = f\"workers_{timestamp}.csv\"\n",
        "\n",
        "    header = [\"id\", \"priority\", \"total_work_time\", \"backoff_count\", \"connection_attempts\", \"connection_probability\", \"backoff_time\"]\n",
        "    # Open CSV file\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=header)\n",
        "        writer.writeheader()\n",
        "        # Loop through workers and write their information to the CSV\n",
        "        for i in range(len(workers)):\n",
        "            current_write = workers[i]\n",
        "            current_write.connection_probability = 0\n",
        "            if current_write.connection_attempts != 0:\n",
        "                current_write.connection_probability = (1-(current_write.backoff_count/current_write.connection_attempts))\n",
        "\n",
        "            worker_info = {\"id\": i, \"priority\": current_write.priority, \"total_work_time\": current_write.total_work_time, \"backoff_count\": current_write.backoff_count, \"connection_attempts\": current_write.connection_attempts, \"connection_probability\": current_write.connection_probability, \"backoff_time\": current_write.init_backoff_time}\n",
        "            writer.writerow(worker_info)\n",
        "\n",
        "    if confirm_filename:\n",
        "        print(f\"Worker information written to {csv_file}\")\n",
        "    return csv_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngBzQ2idtTDw"
      },
      "outputs": [],
      "source": [
        "# DATA CREATION -----------------------------------------------\n",
        "\n",
        "#CONN_LIMIT = 5\n",
        "#SIM_RUNS = 3 #1500\n",
        "#worker_count = 20\n",
        "#server_life = 30\n",
        "#for i in range(SIM_RUNS):\n",
        "#    HIGH_BACKOFF = random.uniform(0.1, 2)\n",
        "#    MED_BACKOFF = random.uniform(.8, 4)\n",
        "#    LOW_BACKOFF = random.uniform(3, 7)\n",
        "#    print(f\"Simulation {i}: Worker count: {worker_count}, High: {HIGH_BACKOFF}, Med: {MED_BACKOFF}, Low: {LOW_BACKOFF}\")\n",
        "\n",
        "    # Instantiate server\n",
        "#    server = Server(limit=CONN_LIMIT)\n",
        "#    workers = simulate(server, worker_count=worker_count, server_life=server_life, backoff_times=[HIGH_BACKOFF, MED_BACKOFF, LOW_BACKOFF])\n",
        "#    write_to_csv(workers)\n",
        "\n",
        "#print(\"Simulation complete. Worker information written to CSV files.\")\n",
        "\n",
        "# Get the current directory\n",
        "current_dir = os.getcwd() + '/content/drive/MyDrive/csmaca_randomized_values'\n",
        "print(current_dir)\n",
        "\n",
        "# # Unzip File\n",
        "# import zipfile\n",
        "# def unzip_file(zip_filepath, extract_to):\n",
        "#     with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
        "#         zip_ref.extractall(extract_to)\n",
        "# unzip_file(current_dir, os.getcwd())\n",
        "\n",
        "# Untar File\n",
        "# import tarfile\n",
        "# def extract_tar(tar_filepath, extract_to):\n",
        "#     with tarfile.open(tar_filepath, 'r') as tar_ref:\n",
        "#         tar_ref.extractall(extract_to)\n",
        "# extract_tar(current_dir, os.getcwd())\n",
        "#!tar -xvf current_dir -C os.getcwd()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bW2XW1jL2-K7"
      },
      "outputs": [],
      "source": [
        "# COMPILE DATA -----------------------------------------------\n",
        "\n",
        "# create data for neural network.\n",
        "# input features: high_target_connection_prob, normal_target_connection_prob, low_target_connection_prob, limit, high_num_workers, normal_num_workers, low_num_workers\n",
        "# output: high_backoff, normal_backoff, low_backoff\n",
        "def create_data(df):\n",
        "    # input features\n",
        "    high_target_connection_prob = df[df['priority'] == 'high']['connection_probability'].mean()\n",
        "    normal_target_connection_prob = df[df['priority'] == 'normal']['connection_probability'].mean()\n",
        "    low_target_connection_prob = df[df['priority'] == 'low']['connection_probability'].mean()\n",
        "    limit = 5\n",
        "    high_num_workers = len(df[df['priority'] == 'high'])\n",
        "    normal_num_workers = len(df[df['priority'] == 'normal'])\n",
        "    low_num_workers = len(df[df['priority'] == 'low'])\n",
        "\n",
        "    # output features (backoff times)\n",
        "    high_backoff = df[df['priority'] == 'high']['backoff_time'].mean()\n",
        "    normal_backoff = df[df['priority'] == 'normal']['backoff_time'].mean()\n",
        "    low_backoff = df[df['priority'] == 'low']['backoff_time'].mean()\n",
        "\n",
        "    #X = [high_target_connection_prob, normal_target_connection_prob, low_target_connection_prob, limit, high_num_workers, normal_num_workers, low_num_workers]\n",
        "    X = [high_target_connection_prob, normal_target_connection_prob, low_target_connection_prob] # let's try with fewer dimensions\n",
        "    Y = [high_backoff, normal_backoff, low_backoff]\n",
        "\n",
        "    # scale the input features to be between 0 and 10\n",
        "    X = [x * 1 for x in X]\n",
        "    # scale the output features to be between 0 and 10\n",
        "    Y = [y * 1 for y in Y]\n",
        "    return X, Y\n",
        "\n",
        "# List all CSV files in the current directory\n",
        "current_dir = \"/content/drive/MyDrive/csmaca_randomized_values\"\n",
        "csv_files = [file for file in os.listdir(current_dir) if file.endswith('.csv')]\n",
        "\n",
        "# Create an empty dataframe to store the compiled outputs\n",
        "compiled_df = pd.DataFrame()\n",
        "\n",
        "# Iterate over each CSV file\n",
        "for idx, csv_file in enumerate(csv_files):\n",
        "    if idx == 1400:\n",
        "      break\n",
        "    # Read the CSV file into a dataframe\n",
        "    df = pd.read_csv(current_dir + \"/\" + csv_file)\n",
        "    # Skip files that don't conform to the data format\n",
        "    if 'priority' not in df.columns or 'total_work_time' not in df.columns or 'backoff_count' not in df.columns or 'connection_attempts' not in df.columns or 'connection_probability' not in df.columns:\n",
        "        print(f\"Skipping {csv_file} as it does not conform to the data format.\")\n",
        "        continue\n",
        "\n",
        "    # Perform the desired operations on the dataframe\n",
        "    X, Y = create_data(df)\n",
        "\n",
        "    # Create a new row for the compiled dataframe\n",
        "    new_row = pd.DataFrame({'CSV File': [csv_file], 'X': [X], 'Y': [Y]})\n",
        "\n",
        "    # Append the new row to the compiled dataframe\n",
        "    compiled_df = pd.concat([compiled_df, new_row], ignore_index=True)\n",
        "\n",
        "# Print the compiled dataframe\n",
        "print(compiled_df)\n",
        "print(compiled_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(tq.__version__)\n",
        "# print python version\n",
        "import sys\n",
        "print(sys.version)"
      ],
      "metadata": {
        "id": "Px11340oWhS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD7H1EAj8h1U"
      },
      "outputs": [],
      "source": [
        "# TORCH QUANTUM NETWORK AND TRAINING -----------------------------------------------\n",
        "import datetime\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import argparse\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torchquantum as tq\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Scale features and targets\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "X = np.array(compiled_df['X'].tolist())\n",
        "Y = np.array(compiled_df['Y'].tolist())\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(Y)\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y_scaled, dtype=torch.float32)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "class RegressionDataset:\n",
        "    def __init__(self, split, X_data, y_data):\n",
        "        self.split = split\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        instance = {\"states\": self.X_data[index], \"Xlabel\": self.y_data[index]}\n",
        "        return instance\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.X_data)\n",
        "\n",
        "\n",
        "class Regression:\n",
        "    def __init__(self, X_train, X_valid, y_train, y_valid):\n",
        "        self.data = {\n",
        "            'train': RegressionDataset('train', X_train, y_train),\n",
        "            'valid': RegressionDataset('valid', X_valid, y_valid)\n",
        "        }\n",
        "\n",
        "    def __getitem__(self, split):\n",
        "        return self.data[split]\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.data)\n",
        "\n",
        "\n",
        "class QModel(tq.QuantumModule):\n",
        "    class QLayer(tq.QuantumModule):\n",
        "        def __init__(self, n_wires, n_blocks):\n",
        "            super().__init__()\n",
        "            self.n_wires = n_wires # qubit count\n",
        "            self.n_blocks = n_blocks # layer count\n",
        "            self.rx_layers = tq.QuantumModuleList()\n",
        "            self.ry_layers = tq.QuantumModuleList()\n",
        "            self.rz_layers = tq.QuantumModuleList()\n",
        "            self.cnot_layers = tq.QuantumModuleList()\n",
        "\n",
        "            for _ in range(n_blocks):\n",
        "                self.rx_layers.append(tq.Op1QAllLayer(op=tq.RX, n_wires=n_wires, has_params=True, trainable=True))\n",
        "                self.ry_layers.append(tq.Op1QAllLayer(op=tq.RY, n_wires=n_wires, has_params=True, trainable=True))\n",
        "                self.rz_layers.append(tq.Op1QAllLayer(op=tq.RZ, n_wires=n_wires, has_params=True, trainable=True))\n",
        "                self.cnot_layers.append(tq.Op2QAllLayer(op=tq.CNOT, n_wires=n_wires, has_params=False, trainable=False, circular=True))\n",
        "\n",
        "        def forward(self, q_device: tq.QuantumDevice):\n",
        "            for k in range(self.n_blocks):\n",
        "                self.rx_layers[k](q_device)\n",
        "                self.ry_layers[k](q_device)\n",
        "                self.rz_layers[k](q_device)\n",
        "                self.cnot_layers[k](q_device)\n",
        "\n",
        "    def __init__(self, n_wires, n_blocks):\n",
        "        super().__init__()\n",
        "        self.q_layer = self.QLayer(n_wires=n_wires, n_blocks=n_blocks)\n",
        "        self.encoder = tq.StateEncoder()\n",
        "        self.measure = tq.MeasureAll(tq.PauliZ)\n",
        "        self.fc_out = torch.nn.Linear(n_wires, 3)  # Adjust the output layer\n",
        "\n",
        "    def forward(self, q_device: tq.QuantumDevice, input_states, use_qiskit=False):\n",
        "        devi = input_states.device\n",
        "        if use_qiskit:\n",
        "            encoder_circs = tq2qiskit_initialize(q_device, input_states.detach().cpu().numpy())\n",
        "            q_layer_circ = tq2qiskit(q_device, self.q_layer)\n",
        "            measurement_circ = tq2qiskit_measurement(q_device, self.measure)\n",
        "            assembled_circs = qiskit_assemble_circs(encoder_circs, q_layer_circ, measurement_circ)\n",
        "            res = self.qiskit_processor.process_ready_circs(self.q_device, assembled_circs).to(devi)\n",
        "        else:\n",
        "            self.encoder(q_device, input_states)\n",
        "            self.q_layer(q_device)\n",
        "            res = self.measure(q_device)\n",
        "        return self.fc_out(res)\n",
        "\n",
        "\n",
        "def train(dataflow, q_device, model, device, optimizer, qiskit=False):\n",
        "    l_data = []\n",
        "    for feed_dict in dataflow[\"train\"]:\n",
        "        inputs = feed_dict[\"states\"].to(device).to(torch.complex64)\n",
        "        targets = feed_dict[\"Xlabel\"].to(device).to(torch.float32)\n",
        "        outputs = model(q_device, inputs, qiskit)\n",
        "        loss = F.mse_loss(outputs, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"loss: {loss.item()}\")\n",
        "        l_data.append(loss.item())\n",
        "\n",
        "    return l_data\n",
        "\n",
        "\n",
        "def valid_test(dataflow, q_device, split, model, device, qiskit):\n",
        "    target_all = []\n",
        "    output_all = []\n",
        "    with torch.no_grad():\n",
        "        for feed_dict in dataflow[split]:\n",
        "            inputs = feed_dict[\"states\"].to(device).to(torch.complex64)\n",
        "            targets = feed_dict[\"Xlabel\"].to(device).to(torch.float32)\n",
        "\n",
        "            outputs = model(q_device, inputs, qiskit)\n",
        "\n",
        "            target_all.append(targets)\n",
        "            output_all.append(outputs)\n",
        "        target_all = torch.cat(target_all, dim=0)\n",
        "        output_all = torch.cat(output_all, dim=0)\n",
        "\n",
        "    loss = F.mse_loss(output_all, target_all)\n",
        "    print(f\"{split} set loss: {loss}\")\n",
        "\n",
        "\n",
        "# MAIN METHOD:\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--pdb\", action=\"store_true\", help=\"debug with pdb\")\n",
        "parser.add_argument(\"--bsz\", type=int, default=8, help=\"batch size for training and validation\")\n",
        "parser.add_argument(\"--n_wires\", type=int, default=3, help=\"number of qubits\")\n",
        "parser.add_argument(\"--n_blocks\", type=int, default=5, help=\"number of blocks\")\n",
        "parser.add_argument(\"--n_train\", type=int, default=500, help=\"number of training samples\")\n",
        "parser.add_argument(\"--n_valid\", type=int, default=300, help=\"number of validation samples\")\n",
        "parser.add_argument(\"--epochs\", type=int, default=250, help=\"number of training epochs\")\n",
        "\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "if args.pdb:\n",
        "    import pdb\n",
        "    pdb.set_trace()\n",
        "\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Prepare datasets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
        "dataset = Regression(X_train, X_valid, y_train, y_valid)\n",
        "\n",
        "dataflow = dict()\n",
        "\n",
        "for split in dataset:\n",
        "    if split == \"train\":\n",
        "        sampler = torch.utils.data.RandomSampler(dataset[split])\n",
        "    else:\n",
        "        sampler = torch.utils.data.SequentialSampler(dataset[split])\n",
        "    dataflow[split] = torch.utils.data.DataLoader(\n",
        "        dataset[split],\n",
        "        batch_size=args.bsz,\n",
        "        sampler=sampler,\n",
        "        num_workers=1,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "model = QModel(n_wires=args.n_wires, n_blocks=args.n_blocks).to(device)\n",
        "\n",
        "n_epochs = args.epochs\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
        "\n",
        "q_device = tq.QuantumDevice(n_wires=args.n_wires)\n",
        "q_device.reset_states(bsz=args.bsz)\n",
        "\n",
        "loss_data = []\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    # train\n",
        "    print(f\"Epoch {epoch}/{n_epochs}, RL: {optimizer.param_groups[0]['lr']}\")\n",
        "    cur_run = train(dataflow, q_device, model, device, optimizer)\n",
        "    loss_data.append(cur_run)\n",
        "\n",
        "    # valid\n",
        "    valid_test(dataflow, q_device, \"valid\", model, device, False)\n",
        "    scheduler.step()\n",
        "\n",
        "try:\n",
        "    from qiskit import IBMQ\n",
        "    from torchquantum.plugin import QiskitProcessor\n",
        "\n",
        "    print(f\"\\nTest with Qiskit Simulator\")\n",
        "    processor_simulation = QiskitProcessor(use_real_qc=False)\n",
        "    model.set_qiskit_processor(processor_simulation)\n",
        "    valid_test(dataflow, q_device, \"test\", model, device, qiskit=True)\n",
        "\n",
        "    # final valid\n",
        "    valid_test(dataflow, q_device, \"valid\", model, device, True)\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdZGvY53KkEn"
      },
      "outputs": [],
      "source": [
        "# EVALUATE MODEL ----------------------------------------------- (THIS NEEDS TO BE UPDATED)\n",
        "# Plot loss_data\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "#%pip install scikit-learn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "plt.plot(loss_data)\n",
        "plt.title('Loss Data')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Evaluate the model\n",
        "with torch.no_grad():\n",
        "    predictions = model(q_device, X_test)\n",
        "    test_loss = criterion(predictions, y_test)\n",
        "    print(f'Test Loss: {test_loss.item()}')\n",
        "\n",
        "# Generate predictions and save the model\n",
        "predictions_unscaled = scaler_y.inverse_transform(predictions.detach().numpy())\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "model_file = f\"model_{timestamp}.pth\"\n",
        "torch.save(model.state_dict(), model_file)\n",
        "print(f\"Model saved to {model_file}\")\n",
        "\n",
        "# Load the model from disk for future use\n",
        "loaded_model = QModel(n_wires=args.n_wires, n_blocks=args.n_blocks)\n",
        "loaded_model.load_state_dict(torch.load(model_file))\n",
        "loaded_model.eval()\n",
        "\n",
        "# Make a prediction for a new data point\n",
        "new_probs = [0.3, 0.2, 0.05]\n",
        "print(f\"Querying model with probabilities: {new_probs}\")\n",
        "new_probs_scaled = scaler_X.transform([new_probs])\n",
        "new_probs_tensor = torch.tensor(new_probs_scaled, dtype=torch.float32)\n",
        "new_prediction = loaded_model(q_device, new_probs_tensor)\n",
        "new_prediction_unscaled = scaler_y.inverse_transform(new_prediction.detach().numpy())\n",
        "print(\"Answer (unscaled):\")\n",
        "print(new_prediction_unscaled)\n",
        "\n",
        "print(f\"To achieve the following connection probabilities: {new_probs}, the backoff times should be: {new_prediction_unscaled[0].tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# request and sweep multiple probabilities\n",
        "# load model from disk\n",
        "loaded_model = QModel(n_wires=args.n_wires, n_blocks=args.n_blocks)\n",
        "loaded_model.load_state_dict(torch.load(model_file))\n",
        "loaded_model.eval()\n",
        "\n",
        "## generate a list of answers\n",
        "probs = [[0.3, 0.2, 0.05], [0.4, 0.3, 0.1], [0.2, 0.2, 0.2],  [0.6, 0.3, 0.1]]\n",
        "# scale new data to be between 0 and 10\n",
        "#new_data = [x * 10 for x in new_data]\n",
        "\n",
        "predictions = []\n",
        "for new_probs in probs:\n",
        "  new_probs_scaled = scaler_X.transform([new_probs])\n",
        "  new_probs_tensor = torch.tensor(new_probs_scaled, dtype=torch.float32)\n",
        "  new_prediction = loaded_model(q_device, new_probs_tensor)\n",
        "  new_prediction_unscaled = scaler_y.inverse_transform(new_prediction.detach().numpy())\n",
        "  print(f\"For probabilities {new_probs} Answer (unscaled) is: {new_prediction_unscaled}\")\n",
        "  predictions.append(new_prediction_unscaled)\n"
      ],
      "metadata": {
        "id": "gAV_gbLQvbWb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}