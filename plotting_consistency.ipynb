{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read each csv file under \"work_output_graphs\" into a dataframe \n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# read CSV files in directory and return dataframe\n",
        "def read_csv_files(directory):\n",
        "    # initialize final_df as empty dataframe\n",
        "    final_df = pd.DataFrame()\n",
        "    counter = 0\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".csv\"):\n",
        "            # extract timestamp from filename and add as column datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "            timestamp = filename.split('_')[1].split('.')[0]\n",
        "            # reverse strftime in format %Y%m%d%H%M%S to epoch timestamp\n",
        "            epoch_ts = int(pd.to_datetime(timestamp, format='%Y%m%d%H%M%S').timestamp())\n",
        "\n",
        "            df = pd.read_csv(os.path.join(directory, filename))\n",
        "\n",
        "            # create new dataframe with timestamp column that has the same number of rows as 'df'\n",
        "            ts_df = pd.DataFrame([epoch_ts] * len(df), columns=['timestamp'])\n",
        "\n",
        "            # concatenate 'ts_df' and 'df' along the columns\n",
        "            df = pd.concat([ts_df, df], axis=1)\n",
        "\n",
        "            # append df to final_df\n",
        "            final_df = pd.concat([final_df, df], ignore_index=True)\n",
        "\n",
        "            # reset df and ts_df\n",
        "            df = pd.DataFrame()\n",
        "            ts_df = pd.DataFrame()\n",
        "            counter += 1\n",
        "    print(f\"Number of CSV files read at path {directory}: {counter}\")\n",
        "    return final_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(os.getcwd())\n",
        "PATH = os.path.join(os.getcwd(), \"csmaca_traditional_data_out\")\n",
        "Q_PATH = os.path.join(os.getcwd(), \"quantum_1kruns_2.31_5.07_7.02\")\n",
        "# sort dataframe by priority\n",
        "trad_df = read_csv_files(PATH)\n",
        "trad_df = trad_df.sort_values(by='priority')\n",
        "print(trad_df)\n",
        "q_df = read_csv_files(Q_PATH)\n",
        "q_df = q_df.sort_values(by='priority')\n",
        "print(q_df)\n",
        "\n",
        "# compare length of trad_df and q_df\n",
        "print(f\"Length of traditional dataframe: {len(trad_df)} vs Length of quantum dataframe: {len(q_df)}\")\n",
        "# Total work time of each type of worker as a function\n",
        "def total_work_time(df, priority):\n",
        "    return df[df['priority'] == priority]['total_work_time'].sum()\n",
        "\n",
        "# Average work time of each type of worker as a function\n",
        "def avg_work_time(df, priority):\n",
        "    return round(df[df['priority'] == priority]['total_work_time'].mean(), 4)\n",
        "\n",
        "# Median work time of each type of worker as a function\n",
        "def median_work_time(df, priority):\n",
        "    return df[df['priority'] == priority]['total_work_time'].median()\n",
        "\n",
        "# number of workers of each type with 0 work time\n",
        "def num_workers_no_work(df, priority):\n",
        "    return len(df[(df['priority'] == priority) & (df['total_work_time'] == 0)])\n",
        "\n",
        "def avg_conn_prob(df, priority):\n",
        "    return round(df[df['priority'] == priority]['connection_probability'].mean(), 4)\n",
        "\n",
        "def print_worker_stats(df, total_work_time, avg_work_time, median_work_time, num_workers_no_work):\n",
        "    print(f\"Total work time for high priority workers: {total_work_time(df, 'high')} seconds\")\n",
        "    print(f\"Total work time for normal priority workers: {total_work_time(df, 'normal')} seconds\")\n",
        "    print(f\"Total work time for low priority workers: {total_work_time(df, 'low')} seconds\")\n",
        "\n",
        "    print(f\"Average work time for high priority workers: {avg_work_time(df, 'high')} seconds\")\n",
        "    print(f\"Average work time for normal priority workers: {avg_work_time(df, 'normal')} seconds\")\n",
        "    print(f\"Average work time for low priority workers: {avg_work_time(df, 'low')} seconds\")\n",
        "\n",
        "    print(f\"Median work time for high priority workers: {median_work_time(df, 'high')} seconds\")\n",
        "    print(f\"Median work time for normal priority workers: {median_work_time(df, 'normal')} seconds\")\n",
        "    print(f\"Median work time for low priority workers: {median_work_time(df, 'low')} seconds\")\n",
        "\n",
        "    print(f\"Number of high priority workers with 0 work time: {num_workers_no_work(df, 'high')}\")\n",
        "    print(f\"Number of normal priority workers with 0 work time: {num_workers_no_work(df, 'normal')}\")\n",
        "    print(f\"Number of low priority workers with 0 work time: {num_workers_no_work(df, 'low')}\")\n",
        "\n",
        "    print(f\"Average connection probability for high priority workers: {avg_conn_prob(df, 'high')}, backoff times: {df[df['priority'] == 'high']['backoff_time'].mean()}\")\n",
        "    print(f\"Average connection probability for normal priority workers: {avg_conn_prob(df, 'normal')}, backoff times: {df[df['priority'] == 'normal']['backoff_time'].mean()}\")\n",
        "    print(f\"Average connection probability for low priority workers: {avg_conn_prob(df, 'low')}, backoff times: {df[df['priority'] == 'low']['backoff_time'].mean()}\")\n",
        "\n",
        "print_worker_stats(trad_df, total_work_time, avg_work_time, median_work_time, num_workers_no_work)\n",
        "print_worker_stats(q_df, total_work_time, avg_work_time, median_work_time, num_workers_no_work)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort the DataFrame by 'timestamp' in descending order\n",
        "trad_df = trad_df.sort_values(by='timestamp', ascending=False)\n",
        "\n",
        "# Select the top 5 rows\n",
        "latest_5_timestamps = trad_df.head(5)\n",
        "\n",
        "# Print the latest 5 timestamps\n",
        "print(\"The latest 5 timestamps in the DataFrame are:\")\n",
        "print(latest_5_timestamps['timestamp'])\n",
        "# print timestamp datatype\n",
        "print(trad_df['timestamp'].dtype)\n",
        "# remove any int64 matching the top timestamp\n",
        "print(trad_df[trad_df['timestamp'] == latest_5_timestamps['timestamp'].values[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_worker_stats(df1, df2, labels):\n",
        "    # Create subplots\n",
        "    fig, axs = plt.subplots(3, 2, figsize=(8, 8))\n",
        "\n",
        "    # Define the bar width and positions\n",
        "    bar_width = 0.35\n",
        "    index = np.arange(3)  # for 'high', 'normal', 'low'\n",
        "\n",
        "    # Define the color palette using tab20\n",
        "    colors = list(plt.cm.tab20.colors)\n",
        "\n",
        "    # Plot total work time by priority\n",
        "    axs[0, 0].bar(index, [total_work_time(df1, 'high'), total_work_time(df1, 'normal'), total_work_time(df1, 'low')], bar_width, label=labels[0], color=[colors[0], colors[2], colors[4]])\n",
        "    axs[0, 0].bar(index + bar_width, [total_work_time(df2, 'high'), total_work_time(df2, 'normal'), total_work_time(df2, 'low')], bar_width, label=labels[1], color=[colors[1], colors[3], colors[5]])\n",
        "    axs[0, 0].set_title('Total Connected Time by Priority')\n",
        "    axs[0, 0].set_ylabel('Total Connected Time (seconds)')\n",
        "    axs[0, 0].set_xticks(index + bar_width / 2)\n",
        "    axs[0, 0].set_xticklabels(['high', 'medium', 'low'])\n",
        "    axs[0, 0].legend()\n",
        "    axs[0, 0].grid()\n",
        "\n",
        "    # Plot number of workers with 0 work time by priority\n",
        "    axs[0, 1].bar(index, [num_workers_no_work(df1, 'high'), num_workers_no_work(df1, 'normal'), num_workers_no_work(df1, 'low')], bar_width, label=labels[0], color=[colors[0], colors[2], colors[4]])\n",
        "    axs[0, 1].bar(index + bar_width, [num_workers_no_work(df2, 'high'), num_workers_no_work(df2, 'normal'), num_workers_no_work(df2, 'low')], bar_width, label=labels[1], color=[colors[1], colors[3], colors[5]])\n",
        "    axs[0, 1].set_title('Number of Workers with 0 Connected Time by Priority')\n",
        "    axs[0, 1].set_ylabel('Number of Workers')\n",
        "    axs[0, 1].set_xticks(index + bar_width / 2)\n",
        "    axs[0, 1].set_xticklabels(['high', 'medium', 'low'])\n",
        "    axs[0, 1].legend()\n",
        "    axs[0, 1].grid()\n",
        "\n",
        "    # Plot average work time by priority\n",
        "    axs[1, 0].bar(index, [avg_work_time(df1, 'high'), avg_work_time(df1, 'normal'), avg_work_time(df1, 'low')], bar_width, label=labels[0], color=[colors[0], colors[2], colors[4]])\n",
        "    axs[1, 0].bar(index + bar_width, [avg_work_time(df2, 'high'), avg_work_time(df2, 'normal'), avg_work_time(df2, 'low')], bar_width, label=labels[1], color=[colors[1], colors[3], colors[5]])\n",
        "    axs[1, 0].set_title('Average Connected Time by Priority')\n",
        "    axs[1, 0].set_ylabel('Average Connected Time (seconds)')\n",
        "    axs[1, 0].set_xticks(index + bar_width / 2)\n",
        "    axs[1, 0].set_xticklabels(['high', 'medium', 'low'])\n",
        "    axs[1, 0].legend()\n",
        "    axs[1, 0].grid()\n",
        "\n",
        "    # Plot connection attempts by priority\n",
        "    axs[1, 1].bar(index, [df1[df1['priority'] == 'high']['connection_attempts'].sum(), df1[df1['priority'] == 'normal']['connection_attempts'].sum(), df1[df1['priority'] == 'low']['connection_attempts'].sum()], bar_width, label=labels[0], color=[colors[0], colors[2], colors[4]])\n",
        "    axs[1, 1].bar(index + bar_width, [df2[df2['priority'] == 'high']['connection_attempts'].sum(), df2[df2['priority'] == 'normal']['connection_attempts'].sum(), df2[df2['priority'] == 'low']['connection_attempts'].sum()], bar_width, label=labels[1], color=[colors[1], colors[3], colors[5]])\n",
        "    axs[1, 1].set_title('Connection Attempts by Priority')\n",
        "    axs[1, 1].set_ylabel('Connection Attempts')\n",
        "    axs[1, 1].set_xticks(index + bar_width / 2)\n",
        "    axs[1, 1].set_xticklabels(['high', 'medium', 'low'])\n",
        "    axs[1, 1].legend()\n",
        "    axs[1, 1].grid()\n",
        "\n",
        "    # Plot connection probability by priority\n",
        "    axs[2, 0].bar(index, [df1[df1['priority'] == 'high']['connection_probability'].mean(), df1[df1['priority'] == 'normal']['connection_probability'].mean(), df1[df1['priority'] == 'low']['connection_probability'].mean()], bar_width, label=labels[0], color=[colors[0], colors[2], colors[4]])\n",
        "    axs[2, 0].bar(index + bar_width, [df2[df2['priority'] == 'high']['connection_probability'].mean(), df2[df2['priority'] == 'normal']['connection_probability'].mean(), df2[df2['priority'] == 'low']['connection_probability'].mean()], bar_width, label=labels[1], color=[colors[1], colors[3], colors[5]])\n",
        "    axs[2, 0].set_title('Connection Probability by Priority')\n",
        "    axs[2, 0].set_ylabel('Connection Probability')\n",
        "    axs[2, 0].set_xticks(index + bar_width / 2)\n",
        "    axs[2, 0].set_xticklabels(['high', 'medium', 'low'])\n",
        "    axs[2, 0].legend()\n",
        "    axs[2, 0].grid()\n",
        "\n",
        "    # Plot backoff count by priority\n",
        "    axs[2, 1].bar(index, [df1[df1['priority'] == 'high']['backoff_count'].sum(), df1[df1['priority'] == 'normal']['backoff_count'].sum(), df1[df1['priority'] == 'low']['backoff_count'].sum()], bar_width, label=labels[0], color=[colors[0], colors[2], colors[4]])\n",
        "    axs[2, 1].bar(index + bar_width, [df2[df2['priority'] == 'high']['backoff_count'].sum(), df2[df2['priority'] == 'normal']['backoff_count'].sum(), df2[df2['priority'] == 'low']['backoff_count'].sum()], bar_width, label=labels[1], color=[colors[1], colors[3], colors[5]])\n",
        "    axs[2, 1].set_title('Backoff Count by Priority')\n",
        "    axs[2, 1].set_ylabel('Backoff Count')\n",
        "    axs[2, 1].set_xticks(index + bar_width / 2)\n",
        "    axs[2, 1].set_xticklabels(['high', 'medium', 'low'])\n",
        "    axs[2, 1].legend()\n",
        "    axs[2, 1].grid()\n",
        "\n",
        "    # Adjust spacing between subplots\n",
        "    plt.tight_layout()\n",
        "    # Save the plot\n",
        "    plt.savefig('stats_by_priority_comparison.png', dpi=300)\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_worker_stats(trad_df, q_df, labels=['Traditional', 'Quantum'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as path_effects\n",
        "from math import pi\n",
        "\n",
        "def normalize_data(data):\n",
        "    \"\"\"Normalize the data to a range of 0 to 1.\"\"\"\n",
        "    min_val = np.min(data)\n",
        "    max_val = np.max(data)\n",
        "    return (data - min_val) / (max_val - min_val)\n",
        "\n",
        "def plot_radar_chart(df1, df2, labels):\n",
        "    # Define the categories and number of variables\n",
        "    categories = ['Total Connected Time', 'Clients with 0 Connected Time', 'Connection Rejected Count', 'Connection Attempts']\n",
        "    num_vars = len(categories) + 1  # +1 for Connection Probability which won't be normalized\n",
        "\n",
        "    # Aggregate the data for each priority level\n",
        "    priorities = ['high', 'normal', 'low']\n",
        "    data1 = []\n",
        "    data2 = []\n",
        "\n",
        "    for priority in priorities:\n",
        "        # Debug prints\n",
        "        print(f\"Priority: {priority}\")\n",
        "        \n",
        "        data1.append([\n",
        "            total_work_time(df1, priority),\n",
        "            num_workers_no_work(df1, priority),\n",
        "            df1[df1['priority'] == priority]['backoff_count'].sum(),\n",
        "            df1[df1['priority'] == priority]['connection_attempts'].sum(),\n",
        "            df1[df1['priority'] == priority]['connection_probability'].mean()  # Raw value\n",
        "        ])\n",
        "        data2.append([\n",
        "            total_work_time(df2, priority),\n",
        "            num_workers_no_work(df2, priority),\n",
        "            df2[df2['priority'] == priority]['backoff_count'].sum(),\n",
        "            df2[df2['priority'] == priority]['connection_attempts'].sum(),\n",
        "            df2[df2['priority'] == priority]['connection_probability'].mean()  # Raw value\n",
        "        ])\n",
        "\n",
        "#    print(\"Raw values for df1:\")\n",
        "#    for priority, values in zip(priorities, data1):\n",
        "#        print(f\"{priority.capitalize()} Priority:\")\n",
        "#        for category, value in zip(categories + ['Connection Probability'], values):\n",
        "#            print(f\"  {category}: {value}\")\n",
        "#\n",
        "#    print(\"\\nRaw values for df2:\")\n",
        "#    for priority, values in zip(priorities, data2):\n",
        "#        print(f\"{priority.capitalize()} Priority:\")\n",
        "#        for category, value in zip(categories + ['Connection Probability'], values):\n",
        "#            print(f\"  {category}: {value}\")\n",
        "\n",
        "    # Normalize the data except for \"Connection Probability\"\n",
        "    data1 = np.array(data1)\n",
        "    data2 = np.array(data2)\n",
        "    combined_data = np.concatenate((data1[:, :4], data2[:, :4]), axis=0)  # Exclude \"Connection Probability\"\n",
        "    normalized_data = normalize_data(combined_data)\n",
        "    data1_normalized = np.hstack((normalized_data[:len(data1)], data1[:, 4:5]))\n",
        "    data2_normalized = np.hstack((normalized_data[len(data1):], data2[:, 4:5]))\n",
        "\n",
        "    # Create subplots for each priority level\n",
        "    fig, axs = plt.subplots(3, 1, figsize=(10, 18), subplot_kw=dict(polar=True))\n",
        "\n",
        "    # Define colors for each priority level\n",
        "    colors = plt.get_cmap('tab20')\n",
        "\n",
        "    priority_colors = {\n",
        "        'high': (colors(0), colors(0)),\n",
        "        'normal': (colors(2), colors(2)),\n",
        "        'low': (colors(4), colors(4))\n",
        "    }\n",
        "\n",
        "    for i, priority in enumerate(priorities):\n",
        "        # Create radar chart for each priority level\n",
        "        values1 = data1_normalized[i].tolist()\n",
        "        values2 = data2_normalized[i].tolist()\n",
        "\n",
        "        # Add the first value to the end to close the circle\n",
        "        values1 += values1[:1]\n",
        "        values2 += values2[:1]\n",
        "\n",
        "        # Compute angle for each category\n",
        "        angles = [n / float(num_vars) * 2 * pi for n in range(num_vars)]\n",
        "        angles += angles[:1]\n",
        "\n",
        "        # Plot data\n",
        "        axs[i].set_theta_offset(pi / 2)\n",
        "        axs[i].set_theta_direction(-1)\n",
        "\n",
        "        # Draw one axe per variable and add labels\n",
        "        axs[i].set_xticks(angles[:-1])\n",
        "        axs[i].set_xticklabels(categories + ['Connection Probability'], fontsize=12)\n",
        "\n",
        "        # Plot data for df1 with dashed line\n",
        "        axs[i].plot(angles, values1, linewidth=2, linestyle='dashed', label=labels[0], color=priority_colors[priority][0])\n",
        "        axs[i].fill(angles, values1, alpha=0.25, color=priority_colors[priority][0])\n",
        "\n",
        "        # Plot data for df2 with solid line and darker border\n",
        "        axs[i].plot(angles, values2, linewidth=2, linestyle='solid', label=labels[1], color=priority_colors[priority][1])\n",
        "        axs[i].fill(angles, values2, alpha=0.25, color=priority_colors[priority][1])\n",
        "        axs[i].plot(angles, values2, linewidth=4, linestyle='solid', color=priority_colors[priority][1], alpha=0.5)  # Darker border\n",
        "\n",
        "        # Add labels for connection probabilities\n",
        "        #text1 = axs[i].text(angles[-2], values1[-2] + 0.1, f'{values1[-2]:.2f}', horizontalalignment='left', size=10, color=priority_colors[priority][0], weight='semibold')\n",
        "        #text2 = axs[i].text(angles[-2], values2[-2] - 0.1, f'{values2[-2]:.2f}', horizontalalignment='left', size=10, color=priority_colors[priority][1], weight='semibold')\n",
        "        #text1.set_path_effects([path_effects.Stroke(linewidth=3, foreground='white'), path_effects.Normal()])\n",
        "        #text2.set_path_effects([path_effects.Stroke(linewidth=3, foreground='white'), path_effects.Normal()])\n",
        "\n",
        "        # Add title and legend\n",
        "        title = 'Medium Priority Clients' if priority == 'normal' else f'{priority.capitalize()} Priority Clients'\n",
        "        axs[i].set_title(title, size=15, color='black', y=1.05)\n",
        "        axs[i].legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "    # Save the plot\n",
        "    plt.savefig('radar_chart_by_priority_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_radar_chart(trad_df, q_df, labels=['TNN', 'QNN'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.lines as mlines\n",
        "\n",
        "def plot_combined_box_plot_by_priority(df1, df2, df1_name, df2_name):\n",
        "    # Combine both dataframes and add a column to distinguish them\n",
        "    df1['source'] = df1_name\n",
        "    df2['source'] = df2_name\n",
        "    combined_df = pd.concat([df1, df2])\n",
        "\n",
        "    # Define the order of the categories\n",
        "    priority_order = ['high', 'normal', 'low']\n",
        "\n",
        "    # Extract colors from the tab20 palette\n",
        "    tab20_colors = plt.get_cmap('tab20').colors\n",
        "\n",
        "    # Define color mapping for each priority and source\n",
        "    color_mapping = {\n",
        "        df1_name: {\n",
        "            'high': tab20_colors[0],\n",
        "            'normal': tab20_colors[2],\n",
        "            'low': tab20_colors[4]\n",
        "        },\n",
        "        df2_name: {\n",
        "            'high': tab20_colors[1],\n",
        "            'normal': tab20_colors[3],\n",
        "            'low': tab20_colors[5]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Create the figure and axis\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "    # Plot box plots for each priority and source\n",
        "    for i, priority in enumerate(priority_order):\n",
        "        df1_data = combined_df[(combined_df['priority'] == priority) & (combined_df['source'] == df1_name)]['total_work_time']\n",
        "        df2_data = combined_df[(combined_df['priority'] == priority) & (combined_df['source'] == df2_name)]['total_work_time']\n",
        "        \n",
        "        # Plot box plot for df1\n",
        "        bp1 = ax.boxplot(df1_data, positions=[i - 0.2], widths=0.4, patch_artist=True)\n",
        "        for box in bp1['boxes']:\n",
        "            box.set_facecolor(color_mapping[df1_name][priority])\n",
        "            box.set_alpha(0.7)\n",
        "        for whisker in bp1['whiskers']:\n",
        "            whisker.set_color(color_mapping[df1_name][priority])\n",
        "        for cap in bp1['caps']:\n",
        "            cap.set_color(color_mapping[df1_name][priority])\n",
        "        for median in bp1['medians']:\n",
        "            median.set_color('black')\n",
        "            # Add median label\n",
        "            median_value = median.get_ydata()[0]\n",
        "            ax.text(i - 0.2, median_value, f'{median_value:.2f}', ha='center', va='bottom', color='black')\n",
        "\n",
        "        # Plot box plot for df2\n",
        "        bp2 = ax.boxplot(df2_data, positions=[i + 0.2], widths=0.4, patch_artist=True)\n",
        "        for box in bp2['boxes']:\n",
        "            box.set_facecolor(color_mapping[df2_name][priority])\n",
        "            box.set_alpha(0.7)\n",
        "        for whisker in bp2['whiskers']:\n",
        "            whisker.set_color(color_mapping[df2_name][priority])\n",
        "        for cap in bp2['caps']:\n",
        "            cap.set_color(color_mapping[df2_name][priority])\n",
        "        for median in bp2['medians']:\n",
        "            median.set_color('black')\n",
        "            # Add median label\n",
        "            median_value = median.get_ydata()[0]\n",
        "            ax.text(i + 0.2, median_value, f'{median_value:.2f}', ha='center', va='bottom', color='black')\n",
        "\n",
        "    # Set the x-axis labels and title\n",
        "    ax.set_xlabel('Priority')\n",
        "    ax.set_ylabel('Total Connected Time (seconds)')\n",
        "    ax.set_title('Box Plot of Connected Time by Priority (Traditional vs Quantum Networks)')\n",
        "    ax.set_xticks(np.arange(len(priority_order)))\n",
        "    ax.set_xticklabels(priority_order)\n",
        "\n",
        "    # Create custom legend handles\n",
        "    legend_handles = []\n",
        "    for source, priority_colors in color_mapping.items():\n",
        "        for priority, color in priority_colors.items():\n",
        "            legend_handles.append(mpatches.Patch(color=color, label=f'{source} ({priority})'))\n",
        "\n",
        "    # Add a custom legend handle for the median lines\n",
        "    median_handle = mlines.Line2D([], [], color='black', label='Median')\n",
        "\n",
        "    # Add the legend\n",
        "    #ax.legend(handles=legend_handles + [median_handle], title='Source and Priority', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_combined_box_plot_by_priority(trad_df, q_df, \"Traditional network\", \"Quantum network\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def plot_bar_plot_by_priority(df1, df2, df1_name, df2_name):\n",
        "    # Calculate average work time by priority for both dataframes\n",
        "    avg_work_time_df1 = df1.groupby('priority')['total_work_time'].mean().reset_index()\n",
        "    avg_work_time_df2 = df2.groupby('priority')['total_work_time'].mean().reset_index()\n",
        "\n",
        "    # Add a column to distinguish the dataframes\n",
        "    avg_work_time_df1['source'] = df1_name\n",
        "    avg_work_time_df2['source'] = df2_name\n",
        "\n",
        "    # Combine the dataframes\n",
        "    combined_df = pd.concat([avg_work_time_df1, avg_work_time_df2])\n",
        "\n",
        "    # Define the order of the categories\n",
        "    priority_order = ['high', 'normal', 'low']\n",
        "\n",
        "    # Sort the combined dataframe by priority\n",
        "    combined_df['priority'] = pd.Categorical(combined_df['priority'], categories=priority_order, ordered=True)\n",
        "    combined_df = combined_df.sort_values('priority')\n",
        "\n",
        "    # Create the bar plot\n",
        "    fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "    # Define the positions for the bars\n",
        "    bar_width = 0.35\n",
        "    index = np.arange(len(priority_order))\n",
        "\n",
        "    # Extract colors from the tab20 palette\n",
        "    tab20_colors = plt.get_cmap('tab20').colors\n",
        "\n",
        "    # Define color mapping for each priority and source\n",
        "    color_mapping = {\n",
        "        'high': [tab20_colors[0], tab20_colors[1]],\n",
        "        'normal': [tab20_colors[2], tab20_colors[3]],\n",
        "        'low': [tab20_colors[4], tab20_colors[5]]\n",
        "    }\n",
        "\n",
        "    # Plot bars for each priority and source\n",
        "    for i, priority in enumerate(priority_order):\n",
        "        df1_mean = combined_df[(combined_df['priority'] == priority) & (combined_df['source'] == df1_name)]['total_work_time'].values[0]\n",
        "        df2_mean = combined_df[(combined_df['priority'] == priority) & (combined_df['source'] == df2_name)]['total_work_time'].values[0]\n",
        "        ax.bar(index[i], df1_mean, bar_width, label=f'{df1_name} ({priority})' if i == 0 else \"\", color=color_mapping[priority][0])\n",
        "        ax.bar(index[i] + bar_width, df2_mean, bar_width, label=f'{df2_name} ({priority})' if i == 0 else \"\", color=color_mapping[priority][1])\n",
        "\n",
        "    # Set the x-axis labels and title\n",
        "    ax.set_xlabel('Priority')\n",
        "    ax.set_ylabel('Average Connected Time (seconds)')\n",
        "    ax.set_title('Average Connected Time by Priority')\n",
        "    ax.set_xticks(index + bar_width / 2)\n",
        "    ax.set_xticklabels(priority_order)\n",
        "    ax.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_bar_plot_by_priority(trad_df, q_df, \"Traditional network\", \"Quantum network\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "def plot_violin_plot_by_priority(df1, df2, df1_name, df2_name):\n",
        "    fig, ax = plt.subplots(figsize=(15, 6))\n",
        "    # Combine both dataframes and add a column to distinguish them\n",
        "    df1['source'] = df1_name\n",
        "    df2['source'] = df2_name\n",
        "    combined_df = pd.concat([df1, df2])\n",
        "\n",
        "    # Define the order of the categories\n",
        "    priority_order = ['high', 'normal', 'low']\n",
        "\n",
        "    sns.violinplot(x='priority', y='total_work_time', hue='source', data=combined_df, split=True, ax=ax, palette='tab20', order=priority_order)\n",
        "\n",
        "    ax.set_title('Violin Plot of Work Time by Priority')\n",
        "    ax.set_ylabel('Total Work Time (seconds)')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_violin_plot_by_priority(trad_df, q_df, \"traditional network\", \"quantum network\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def plot_violin_plot_by_priority(df1, df2, df1_name, df2_name):\n",
        "    fig, ax = plt.subplots(figsize=(15, 6))\n",
        "    \n",
        "    # Combine both dataframes and add a column to distinguish them\n",
        "    df1['source'] = df1_name\n",
        "    df2['source'] = df2_name\n",
        "    combined_df = pd.concat([df1, df2])\n",
        "\n",
        "    # Define the order of the categories\n",
        "    priority_order = ['high', 'normal', 'low']\n",
        "\n",
        "    # Extract colors from the tab20 palette\n",
        "    tab20_colors = plt.get_cmap('tab20').colors\n",
        "\n",
        "    # Define color mapping for each priority and source\n",
        "    color_mapping = {\n",
        "        'high': [tab20_colors[0], tab20_colors[1]],\n",
        "        'normal': [tab20_colors[2], tab20_colors[3]],\n",
        "        'low': [tab20_colors[4], tab20_colors[5]]\n",
        "    }\n",
        "\n",
        "    # Plot violins for each priority and source\n",
        "    for i, priority in enumerate(priority_order):\n",
        "        df1_data = combined_df[(combined_df['priority'] == priority) & (combined_df['source'] == df1_name)]['total_work_time']\n",
        "        df2_data = combined_df[(combined_df['priority'] == priority) & (combined_df['source'] == df2_name)]['total_work_time']\n",
        "        \n",
        "        # Plot violin for df1\n",
        "        parts1 = ax.violinplot(df1_data, positions=[i], widths=0.4, showmeans=False, showmedians=False)\n",
        "        for pc in parts1['bodies']:\n",
        "            pc.set_facecolor(color_mapping[priority][0])\n",
        "            pc.set_edgecolor('black')\n",
        "            pc.set_alpha(0.5)  # Set transparency\n",
        "\n",
        "        # Plot violin for df2\n",
        "        parts2 = ax.violinplot(df2_data, positions=[i], widths=0.4, showmeans=False, showmedians=False)\n",
        "        for pc in parts2['bodies']:\n",
        "            pc.set_facecolor(color_mapping[priority][1])\n",
        "            pc.set_edgecolor('black')\n",
        "            pc.set_alpha(0.5)  # Set transparency\n",
        "\n",
        "    # Set the x-axis labels and title\n",
        "    ax.set_xlabel('Priority')\n",
        "    ax.set_ylabel('Total Work Time (seconds)')\n",
        "    ax.set_title('Violin Plot of Work Time by Priority')\n",
        "    ax.set_xticks(np.arange(len(priority_order)))\n",
        "    ax.set_xticklabels(priority_order)\n",
        "    ax.legend([df1_name, df2_name], loc='upper right')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_violin_plot_by_priority(trad_df, q_df, \"traditional network\", \"quantum network\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "def plot_combined_violin_plot_by_priority(df1, df2, df1_name, df2_name):\n",
        "    # Combine both dataframes and add a column to distinguish them\n",
        "    df1['source'] = df1_name\n",
        "    df2['source'] = df2_name\n",
        "    combined_df = pd.concat([df1, df2])\n",
        "\n",
        "    # Define the order of the categories\n",
        "    priority_order = ['high', 'normal', 'low']\n",
        "\n",
        "    # Create the figure and axis\n",
        "    fig, ax = plt.subplots(figsize=(7, 6))  # Adjusted figure size to be narrower\n",
        "\n",
        "    # Plot the violin plot\n",
        "    sns.violinplot(x='priority', y='connection_probability', hue='source', data=combined_df, order=priority_order, palette='tab20', split=True, ax=ax)\n",
        "\n",
        "    # Calculate and label medians and averages\n",
        "    tab20_colors = plt.get_cmap('tab20').colors\n",
        "    for i, priority in enumerate(priority_order):\n",
        "        for j, (source, color) in enumerate(zip([df1_name, df2_name], [tab20_colors[0], tab20_colors[1]])):\n",
        "            median_val = combined_df[(combined_df['priority'] == priority) & (combined_df['source'] == source)]['connection_probability'].median()\n",
        "            mean_val = combined_df[(combined_df['priority'] == priority) & (combined_df['source'] == source)]['connection_probability'].mean()\n",
        "            offset = -0.2 if j == 0 else 0.2  # Offset for placing the label on the corresponding side\n",
        "            ax.text(i + offset, mean_val, f'{mean_val:.2f}', ha='center', va='bottom', color='black', fontsize=10, weight=None, rotation=30)\n",
        "            ax.hlines(mean_val, i - 0.2, i + 0.2, colors=color, linestyles='dashed', linewidth=1)\n",
        "\n",
        "    # Set the x-axis labels and title\n",
        "    ax.set_xlabel('Priority')\n",
        "    ax.set_ylabel('Connection Probability')\n",
        "    ax.set_title('Connection Probability by Priority')\n",
        "    ax.grid(True)\n",
        "\n",
        "\n",
        "    # Capitalize x-tick labels\n",
        "    ax.set_xticklabels([label.get_text().capitalize() for label in ax.get_xticklabels()])\n",
        "\n",
        "\n",
        "    # Add the legend\n",
        "    # Create custom legend handles\n",
        "    legend_handles = [\n",
        "        plt.Line2D([0], [0], color=tab20_colors[0], lw=4, label=f'{df1_name}'),\n",
        "        plt.Line2D([0], [0], color=tab20_colors[1], lw=4, label=f'{df2_name}'),\n",
        "        plt.Line2D([0], [0], color='black', lw=2, linestyle='dashed', label='Average')\n",
        "    ]\n",
        "\n",
        "    # Add the legend\n",
        "    ax.legend(handles=legend_handles, title='Source', loc='upper right')  # Adjusted bbox_to_anchor\n",
        "\n",
        "    plt.savefig('connection_probability_violin_graphs.png')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_combined_violin_plot_by_priority(trad_df, q_df, \"Traditional Network\", \"Quantum Network\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "expected = np.array([\n",
        "    np.array([0.3, 0.2, 0.05]),\n",
        "    np.array([0.4, 0.2, 0.1]),\n",
        "    np.array([0.4, 0.2, 0.1]),\n",
        "    np.array([0.2, 0.2, 0.2]),\n",
        "    np.array([0.6, 0.3, 0.1]),\n",
        "    \n",
        "])\n",
        "observed = np.array([\n",
        "    np.array([0.35, 0.20, 0.14]),\n",
        "    np.array([0.44, 0.18, 0.11]),\n",
        "    np.array([0.18, 0.27, 0.23]),\n",
        "    np.array([0.45, 0.22, 0.18]),\n",
        "])\n",
        "\n",
        "for i in range(len(expected)-1):\n",
        "    print(f\"Euclidean distance between expected and observed values for row {i}: {np.linalg.norm(expected[i] - observed[i])}\")\n",
        "    print(f\"Cosine similarity between expected and observed values for row {i}: {np.dot(expected[i], observed[i]) / (np.linalg.norm(expected[i]) * np.linalg.norm(observed[i]))}\")\n",
        "\n",
        "tnn = [1.06, 3.8, 6.1]  # Network 1 output\n",
        "qnn = [1.2, 2.6, 5.0]  # Network 2 output\n",
        "# calculate euclidean distance and cosine similarity between tnn and qnn\n",
        "print(f\"Euclidean distance between tnn and qnn: {np.linalg.norm(np.array(tnn) - np.array(qnn))}\")\n",
        "print(f\"Cosine similarity between tnn and qnn: {np.dot(tnn, qnn) / (np.linalg.norm(tnn) * np.linalg.norm(qnn))}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
